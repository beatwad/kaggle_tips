{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1852888e",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pykakasi\n",
    "import numpy as np\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc226a0b",
   "metadata": {},
   "source": [
    "# Impute NaN data with KNNImputer using custom fucntion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf2beb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "features = [fe for fe in train_df.columns if fe not in ['Id','Class']]\n",
    "\n",
    "def cosine_dist(X, Y, metric='cosine', missing_values=np.nan, **kwargs):\n",
    "    X[np.isnan(X)]=0\n",
    "    Y[np.isnan(Y)]=0\n",
    "    return pairwise_distances(X=X.reshape(-1, 1), \n",
    "                              Y=Y.reshape(-1, 1), \n",
    "                              metric='cosine').sum()\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5, metric=cosine_dist)\n",
    "imputer.fit_transform(train_df[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307c952",
   "metadata": {},
   "source": [
    "## Is text English?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd6d8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    ss = \"ª°⭐•®’—–™&\\xa0\\xad\\xe2\\xf0\"  # special characters\n",
    "    s = str(s).lower()\n",
    "    for k in range(len(ss)):\n",
    "        s = s.replace(ss[k], \"\")\n",
    "    try:\n",
    "        s.encode(encoding=\"utf-8\").decode(\"ascii\")\n",
    "    except UnicodeDecodeError:\n",
    "        # not english; check it still not english if western european characters are removed\n",
    "        ss = \"éáñóüäýöçãõúíàêôūâşè\"\n",
    "        for k in range(len(ss)):\n",
    "            s = s.replace(ss[k], \"\")\n",
    "        try:\n",
    "            s.encode(encoding=\"utf-8\").decode(\"ascii\")\n",
    "        except UnicodeDecodeError:\n",
    "            return 3  # really not english\n",
    "        else:\n",
    "            return 2  # spanish/french?\n",
    "    else:\n",
    "        return 1  # english"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a457a62c",
   "metadata": {},
   "source": [
    "# Convert japaneese alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e16530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_japanese_alphabet(df):\n",
    "    kakasi = pykakasi.kakasi()\n",
    "    kakasi.setMode('H', 'a')  # Convert Hiragana into alphabet\n",
    "    kakasi.setMode('K', 'a')  # Convert Katakana into alphabet\n",
    "    kakasi.setMode('J', 'a')  # Convert Kanji into alphabet\n",
    "    conversion = kakasi.getConverter()\n",
    "\n",
    "    def convert(row):\n",
    "        for column in [\"name\", \"address\", \"city\", \"state\"]:\n",
    "            try:\n",
    "                row[column] = conversion.do(row[column])\n",
    "            except Exception:\n",
    "                pass\n",
    "        return row\n",
    "\n",
    "    df = df.apply(convert, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea22fa03",
   "metadata": {},
   "source": [
    "# Process some categorical like features (couple of categories in one string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1966dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categories(cat, split=\" \"):\n",
    "    cat = [x for x in str(cat).split(split) if cat != \"\" and len(x) >= 2]\n",
    "    # Keep only letters\n",
    "    cat = [re.sub(r\"[^a-zA-Z]\", \" \", x) for x in cat]\n",
    "    # Delete multi space\n",
    "    cat = [re.sub(\"\\\\s+\", \" \", x).strip() for x in cat]\n",
    "    return cat\n",
    "\n",
    "# Function to fill missing categories\n",
    "def find_cat(name, Key_words_for_cat):\n",
    "    name_list = process_categories(unidecode(str(name).lower()))\n",
    "    for cat, wordlist in Key_words_for_cat.items():\n",
    "        if any(name_word in name_list for name_word in wordlist):\n",
    "            return cat\n",
    "    return \"\"\n",
    "\n",
    "def process_text_cat(text):\n",
    "    text = unidecode(text.lower())\n",
    "    res = \" \".join([re.sub(r\"[^a-zA-Z]\", \" \", x).strip() for x in text.split()])\n",
    "    return re.sub(\"\\\\s+\", \" \", res).strip()\n",
    "\n",
    "\n",
    "def simplify_cat(categories, Cat_regroup):\n",
    "    categories = str(categories).lower()\n",
    "    if categories in (\"\", \"nan\"):\n",
    "        return -1\n",
    "    for cat in categories.split(\",\"):\n",
    "        cat = process_text_cat(cat)\n",
    "        for i, Liste in enumerate(Cat_regroup):\n",
    "            if any(cat == x for x in Liste):\n",
    "                return i + 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0539fd5b",
   "metadata": {},
   "source": [
    "# Remove special symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0719c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def st(x, remove_space=False):\n",
    "    # turn to latin alphabet\n",
    "    x = unidecode(str(x))\n",
    "    # lower case\n",
    "    x = x.lower()\n",
    "    # remove symbols\n",
    "    x = x.replace('\"', \"\")\n",
    "    ss = \",:;'/-+&()!#$%*.|\\@`~^<>?[]{}_=\\n\"  # noqa\n",
    "    if remove_space:\n",
    "        ss = \" \" + ss\n",
    "    for i in range(len(ss)):\n",
    "        x = x.replace(ss[i], \"\")\n",
    "    return x\n",
    "\n",
    "\n",
    "def rem_expr(x):\n",
    "    x = str(x)\n",
    "    x = x.replace(\"™\", \"\")  # tm\n",
    "    x = x.replace(\"®\", \"\")  # r\n",
    "    x = x.replace(\"ⓘ\", \"\")  # i\n",
    "    x = x.replace(\"©\", \"\")  # c\n",
    "    return x\n",
    "\n",
    "\n",
    "def rem_abr(x):\n",
    "    x = str(x)\n",
    "    if \"(\" in x and \")\" in x:  # there are brakets\n",
    "        i = x.find(\"(\")\n",
    "        j = x.find(\")\")\n",
    "        if j > i + 1 and j - i < 10 and len(x) - (j - i) > 9:  # remainder is long enough\n",
    "            s = x[i + 1: j]\n",
    "            # clean it\n",
    "            ss = \" ,:;'/-+&()!#$%*.|`~^<>?[]{}_=\\n\"\n",
    "            for k in range(len(ss)):\n",
    "                s = s.replace(ss[k], \"\")\n",
    "            if s == s.upper():  # all caps (and/or numbers)\n",
    "                x = x[:i] + x[j + 1:]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017f00c",
   "metadata": {},
   "source": [
    "# Clean phones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b21bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_phone(text):\n",
    "    text = str(text)\n",
    "    if text == \"nan\":\n",
    "        return \"\"\n",
    "    L = []\n",
    "    for char in text:\n",
    "        if char.isdigit():\n",
    "            L.append(char)\n",
    "    res = \"\".join(L)[-10:].zfill(10)\n",
    "    if len(res) > 0:\n",
    "        return res\n",
    "    else:\n",
    "        return text\n",
    "    \n",
    "train[\"phone\"] = train[\"phone\"].apply(lambda text: process_phone(text))\n",
    "# all matches of last 9 digits look legit - drop leading digit\n",
    "train[\"phone\"] = train[\"phone\"].str[1:]\n",
    "# set invalid numbers to empty\n",
    "idx = (train[\"phone\"] == \"000000000\") | (train[\"phone\"] == \"999999999\")\n",
    "train[\"phone\"].loc[idx] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfc0cc1",
   "metadata": {},
   "source": [
    "# Clean URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce56f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"url\"] = train[\"url\"].str[:129]  # cap length at 129\n",
    "train[\"url\"].loc[train[\"url\"] == \"nan\"] = \"\"\n",
    "idx = train[\"url\"].str[:8] == \"httpswww\"\n",
    "train[\"url\"].loc[idx] = train[\"url\"].str[8:].loc[idx]\n",
    "idx = train[\"url\"].str[:7] == \"httpwww\"\n",
    "train[\"url\"].loc[idx] = train[\"url\"].str[7:].loc[idx]\n",
    "idx = train[\"url\"].str[:5] == \"https\"\n",
    "train[\"url\"].loc[idx] = train[\"url\"].str[5:].loc[idx]\n",
    "idx = train[\"url\"].str[:4] == \"http\"\n",
    "train[\"url\"].loc[idx] = train[\"url\"].str[4:].loc[idx]\n",
    "train[\"url\"].loc[train[\"url\"] == \"nan\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8bacd",
   "metadata": {},
   "source": [
    "# Remove common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d7541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nums(x):  # remove st/nd/th number extensions\n",
    "    words = [\n",
    "        \"1st\",\n",
    "        \"2nd\",\n",
    "        \"3rd\",\n",
    "        \"4th\",\n",
    "        \"5th\",\n",
    "        \"6th\",\n",
    "        \"7th\",\n",
    "        \"8th\",\n",
    "        \"9th\",\n",
    "        \"0th\",\n",
    "        \"1th\",\n",
    "        \"2th\",\n",
    "        \"3th\",\n",
    "        \"4 th\",\n",
    "        \"5 th\",\n",
    "        \"6 th\",\n",
    "        \"7 th\",\n",
    "        \"8 th\",\n",
    "        \"9 th\",\n",
    "        \"0 th\",\n",
    "        \"1 th\",\n",
    "        \"2 th\",\n",
    "        \"3 th\",\n",
    "        \"1 st\",\n",
    "        \"2 nd\",\n",
    "        \"3 nd\",\n",
    "    ]\n",
    "    for word in words:\n",
    "        x = x.replace(word, word[0])\n",
    "    return x\n",
    "\n",
    "def rem_words(x):  # remove common words without much meaning\n",
    "    words = [\n",
    "        \"the\",\n",
    "        \"de\",\n",
    "        \"of\",\n",
    "        \"da\",\n",
    "        \"la\",\n",
    "        \"a\",\n",
    "        \"an\",\n",
    "        \"and\",\n",
    "        \"at\",\n",
    "        \"b\",\n",
    "        \"el\",\n",
    "        \"las\",\n",
    "        \"los\",\n",
    "        \"no\",\n",
    "        \"di\",\n",
    "        \"by\",\n",
    "        \"le\",\n",
    "        \"del\",\n",
    "        \"in\",\n",
    "        \"co\",\n",
    "        \"inc\",\n",
    "        \"llc\",\n",
    "        \"llp\",\n",
    "        \"ltd\",\n",
    "        \"on\",\n",
    "        \"der\",\n",
    "        \" das\",\n",
    "        \"die\",\n",
    "    ]\n",
    "    for word in words:\n",
    "        x = x.replace(\" \" + word + \" \", \" \")  # middle\n",
    "        if x[: len(word) + 1] == word + \" \":  # start\n",
    "            x = x[len(word) + 1:]\n",
    "        if x[-len(word) - 1:] == \" \" + word:  # end\n",
    "            x = x[: -len(word) - 1]\n",
    "    return x\n",
    "\n",
    "# select capitals only, or first letter of each word (which could have been capital)\n",
    "def get_caps_leading(name):\n",
    "    name = unidecode(name)\n",
    "    if name[:3].lower() == \"the\":  # drop leading 'the' - do not include it in name\n",
    "        name = name[3:]\n",
    "    name = rem_words(\n",
    "        name\n",
    "    )  # remove common words without much meaning; assume they are always lowercase\n",
    "    name = clean_nums(name)  # remove st/nd/th number extensions\n",
    "    name = [x for x in str(name).split(\" \") if name != \"\" and len(x) >= 2]\n",
    "    # keep only capitals or first letters\n",
    "    name = [re.findall(r\"^[a-z]|[A-Z]\", x) for x in name]\n",
    "    # merge\n",
    "    name = [\"\".join(x) for x in name]\n",
    "    name = \"\".join(name)\n",
    "    return name.lower()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
