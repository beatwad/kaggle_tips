{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM prompt hub\n",
    "\n",
    "https://smith.langchain.com/hub\n",
    "\n",
    "# Prompt library from Anthropic\n",
    "\n",
    "https://docs.anthropic.com/en/prompt-library/library\n",
    "\n",
    "# Examples of production-ready prompts\n",
    "\n",
    "https://github.com/anthropics/anthropic-cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt guides\n",
    "\n",
    "- [OpenAI/ChatGPT course](https://learnprompting.org/courses/chatgpt-for-everyone)\n",
    "- [Anthropic/Claude course](https://docs.google.com/spreadsheets/d/19jzLgRruG9kjUQNKtCg1ZjdD6l6weA6qRXG5zLIAhC8/edit#gid=150872633)\n",
    "- [Google/Gemini guide + use cases](https://services.google.com/fh/files/misc/gemini-for-google-workspace-prompting-guide-101.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt writing tips\n",
    "\n",
    "**Prompt compontents**:\n",
    "\n",
    "- **Role**: helps to control the behaviour of the model.\n",
    "\n",
    "- **Instruction**: expand on the specific tasks you want LLM to do, as well as any rules that LLM might have to follow. \n",
    "This is also where you can give LLM an \"out\" if it doesn't have an answer or doesn't know.\n",
    "\n",
    "- **Context**: give LLM context about the role it should take on or what goals and overarching tasks you want it to undertake with the prompt.\n",
    "E.g.: \"You will be acting as an AI career coach named Joe created by the company AdAstra Careers. Your goal is to give career advice to users. \n",
    "You will be replying to users who are on the AdAstra site and who will be confused if you don't respond in the character of Joe.\"\n",
    "\n",
    "- **Tone context**: if important to the interaction, tell Claude what tone it should use.\n",
    "E.g.: \"You should maintain a friendly customer service tone.\"\n",
    "\n",
    "- **Examples**: provide LLM with at least one example of an ideal response that it can emulate. Encase this in <example></example> XML tags. \n",
    "Feel free to provide multiple examples. If you do provide multiple examples, give LLM context about what it is an example of, \n",
    "and enclose each example in its own set of XML tags.\n",
    "\n",
    "- **Input data to process**: if there is data that LLM needs to process within the prompt (e.g. user conversation history), include it here \n",
    "within relevant XML tags. Feel free to include multiple pieces of data, but be sure to enclose each in its own set of XML tags.\n",
    "\n",
    "- **Immediate task description or request**: \"remind\" or tell LLM exactly what it's expected to immediately do to fulfill the prompt's task. \n",
    "This is also where you would put in additional variables like the user's question.\n",
    "E.g.: \"How do you respond to the user's question?\".\n",
    "\n",
    "- **Precognition (thinking step by step)**: For tasks with multiple steps, it's good to tell LLM to think step by step before giving an answer. \n",
    "Sometimes, you might have to even say \"Before you give your answer...\" just to make sure LLM does this first.\n",
    "E.g.: \"Think about your answer first before you respond.\"\n",
    "\n",
    "- **Output formatting**: If there is a specific way you want LLM's response formatted, clearly tell LLM what that format is. \n",
    "E.g.: \"Put your response in <response></response> tags.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Main tips\n",
    "\n",
    "- Use natural language. Write as if you’re speaking to another person. Express complete thoughts in\n",
    "full sentences.\n",
    "\n",
    "- Be specific and iterate. Tell LLM what you need it to do (summarize, write, change the\n",
    "tone, create). Provide as much context as possible.\n",
    "\n",
    "- Be concise and avoid complexity. State your request in brief — but specific — language. Avoid jargon.\n",
    "\n",
    "- The most successful prompts average around 21 words.\n",
    "\n",
    "- Make it a conversation. Fine-tune your prompts if the results don’t meet your expectations or if you believe\n",
    "there’s room for improvement. Use follow-up prompts and an iterative process of review and refinement to\n",
    "yield better results.\n",
    "\n",
    "- If LLM doesn't have enough information - give an internet access to it, use Wikipedia articles or your own database\n",
    "to help the model to collect more information about the question you ask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Break it up. If you want LLM to perform several related tasks, break them into separate prompts. \n",
    "For example if LLM can't fullfill task to answer the question and format it, you can at first ask\n",
    "it to answer this question and after that format its previous answer. \n",
    "\n",
    "- Chaining prompts. If LLM returns incorrect answer, use your question and its answer as prompt and ask LLM to find\n",
    "the mistakes in this answer and fix them.\n",
    "\n",
    "- Give constraints. To generate specific results, include details in your prompt such as character count limits\n",
    "or the number of options you’d like to generate.\n",
    "\n",
    "- Assign a role. To encourage creativity, assign a role. You can do this by starting your prompt with language\n",
    "like: “You are the head of a creative department for a leading advertising agency …”\n",
    "\n",
    "- Ask for feedback. In your conversation with LLM, tell it that you’re giving it a project,\n",
    "include all the details you have and everything you know, and then describe the output you want. Continue the\n",
    "conversation by asking questions like, “What questions do you have for me that would help you provide the\n",
    "best output?”\n",
    "\n",
    "- Consider tone. Tailor your prompts to suit your intended audience and desired tone of the content.\n",
    "Ask for a specific tone such as formal, informal, technical, creative, or casual in the output.\n",
    "\n",
    "- Say it another way. Fine-tune your prompts if the results don’t meet your expectations or if you believe\n",
    "there’s room for improvement. An iterative process of review and refinement often yields better results.\n",
    "\n",
    "- ChatGPT Plus subscribers can use Custom Instructions to give additional information to LLM and set its output format. \n",
    "For example you can give your name and job title to it and it will always sign the email letters correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If you want LLM to work with part of text, enclose it in triple quotes ``` or with XML borders like <text_part> ... </text_part>, etc.\n",
    "\n",
    "- Check your prompt for typos and grammatical errors. LLM is usually sensitive to them and can give incorrect results.\n",
    "\n",
    "- Order of sentences matters. In most situations (but not all, confusingly enough), LLM is more likely to choose the second of two options, possibly because in its training data from the web, second options were more likely to be correct.\n",
    "\n",
    "- If answer is not satisfying you can ask model to think step by step, e.g.: \"Name a famous movie starring an actor who was born in the year 1956. First brainstorm about some actors and their birth years in <brainstorm> tags, then give your answer.\"\n",
    "\n",
    "- Few-shot learning: give LLM 2-3 examples of how it should answer your question and format its output.\n",
    "\n",
    "- Hallucinations: LLM can sometimes come up with an answer based on nothing, how to tackle with them:\n",
    "\n",
    "    - ask LLM to only answer if it knows the answer with certainty\n",
    "\n",
    "    - a great way to reduce hallucinations on long documents is to make LLM gather evidence first, e.g. we tell LLM \n",
    "    to first extract relevant quotes, then base its answer on those quotes: \n",
    "    Example: \"Please read the below document. Then, in <scratchpad> tags, pull the most relevant quote from the document \n",
    "    and consider whether it answers the user's question or whether it lacks sufficient detail. \n",
    "    Then write a brief numerical answer in <answer> tags.\"\n",
    "\n",
    "    - add the internet access or RAG\n",
    "\n",
    "    - low temperature of LLMs responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of the prompt\n",
    "\n",
    "You are coding assistance and teaching bot. \n",
    "\n",
    "At first read the code and understand what it should do from the comments and function names. \n",
    "\n",
    "Brainstorm how you would solve this task.\n",
    "\n",
    "Then if this code is incorrect, write why it's incorrect and offer guiding corrections if appropriate.\n",
    "\n",
    "Use your previous brainstorm insights.\n",
    "\n",
    "Code is encased in &lt;code&gt;&lt;/code&gt; XML tags.\n",
    "\n",
    "Enclose the code in your answer in triple quotes ```\n",
    "\n",
    "&lt;code&gt;\n",
    "\n",
    "&#35; Function to print multiplicative inverses\n",
    "\n",
    "def print_multiplicative_inverses(x, n):\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;for i in range(n):\n",
    "  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;print(x / i)\n",
    "    \n",
    "&lt;/code&gt;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 levels of text splitting\n",
    "\n",
    "Video\n",
    "\n",
    "https://www.youtube.com/watch?v=8OJC21T2SL4&t=1962s\n",
    "\n",
    "Notebook\n",
    "\n",
    "https://github.com/FullStackRetrieval-com/RetrievalTutorials/blob/main/tutorials/LevelsOfTextSplitting/5_Levels_Of_Text_Splitting.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
