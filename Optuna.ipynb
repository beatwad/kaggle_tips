{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f0b091",
   "metadata": {},
   "source": [
    "# Optuna for CatBoostRegressor\n",
    "\n",
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d83036",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_pickle(\"checkpoint_final.pkl\")\n",
    "# Downcast the float columns to reduce RAM usage\n",
    "floatcols = [c for c in matrix.columns if matrix[c].dtype==\"float32\"]\n",
    "matrix[floatcols] = matrix[floatcols].astype(\"float16\")\n",
    "matrix['item_cnt_month'] = matrix['item_cnt_month'].clip(0,20)\n",
    "keep_from_month = 2  # The first couple of months are dropped because of distortions to their features (e.g. wrong item age)\n",
    "val_month = 33\n",
    "test_month = 34\n",
    "\n",
    "dropcols = [\n",
    "    \"shop_id\",\n",
    "    \"item_id\",\n",
    "    \"new_item\",\n",
    "]  # The features are dropped to reduce overfitting\n",
    "\n",
    "categoricals = [\n",
    "    \"item_category_id\",\n",
    "    \"month\",\n",
    "]\n",
    "matrix[categoricals] = matrix[categoricals].astype(\"category\") \n",
    "train = matrix.drop(columns=dropcols).loc[matrix.date_block_num < val_month, :]\n",
    "train = train[train.date_block_num >= keep_from_month]\n",
    "val = matrix.drop(columns=dropcols).loc[matrix.date_block_num == val_month, :]\n",
    "test = matrix.drop(columns=dropcols).loc[matrix.date_block_num == test_month, :]\n",
    "\n",
    "X_train = train.drop(columns=\"item_cnt_month\")\n",
    "y_train = train.item_cnt_month\n",
    "X_val = val.drop(columns=\"item_cnt_month\")\n",
    "y_val = val.item_cnt_month\n",
    "X_test = test.drop(columns=\"item_cnt_month\")\n",
    "\n",
    "del(matrix, train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e23e5",
   "metadata": {},
   "source": [
    "Set objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d184370",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    train_pool = Pool(X_train, y_train, cat_features=categoricals)\n",
    "    val_pool = Pool(X_val, y_val, cat_features=categoricals)\n",
    "    \n",
    "    # Parameters\n",
    "    params = {\n",
    "        'iterations' : trial.suggest_int('iterations', 300, 1200, step=100),                         \n",
    "        'l2_leaf_reg': trial.suggest_loguniform(\"l2_leaf_reg\", 1e-8, 100),\n",
    "        'learning_rate' :trial.suggest_loguniform('learning_rate', 1e-3, 3e-1),             \n",
    "        'grow_policy':trial.suggest_categorical('grow_policy', ['SymmetricTree', 'Depthwise', 'Lossguide']), \n",
    "        'depth' : trial.suggest_int('depth', 4, 10),  # max tree depth\n",
    "        'random_strength' :trial.suggest_int('random_strength', 0, 100), # The amount of randomness to use \n",
    "                                                                         # for scoring splits when the tree structure\n",
    "                                                                         # is selected. Helps to avoid overfitting\n",
    "        'max_bin':trial.suggest_categorical('max_bin', [2,3,4,5,10,20,32,64]), # The number of splits for \n",
    "                                                                               # numerical features\n",
    "        \n",
    "        'bagging_temperature' :trial.suggest_loguniform('bagging_temperature', 0.01, 100.00), # assigns random \n",
    "                                                                                              # weights to objects\n",
    "    }\n",
    "    \n",
    "    if params['grow_policy'] == 'SymmetricTree': \n",
    "        params['boosting_type']= trial.suggest_categorical('boosting_type', ['Ordered', 'Plain'])\n",
    "    else:\n",
    "        params['boosting_type'] = 'Plain'\n",
    "    \n",
    "    # Learning\n",
    "    model = cat.CatBoostRegressor(\n",
    "        loss_function='RMSE',\n",
    "        eval_metric='RMSE',\n",
    "        task_type='GPU',\n",
    "        random_seed=42,\n",
    "        od_type='Iter',\n",
    "        od_wait=30,\n",
    "        metric_period=100,\n",
    "        **params\n",
    "    )        \n",
    "    model.fit(train_pool)\n",
    "    # Predict\n",
    "    preds = model.predict(val_pool)\n",
    "    # Evaluation\n",
    "    rmse = mean_squared_error(y_val, preds, squared=False)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b93d20d",
   "metadata": {},
   "source": [
    "Launch Optuna study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5e1e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, timeout=3600) # change timeout if you want to make optimization process longer\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ba1624",
   "metadata": {},
   "source": [
    "Create a dataframe from the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20fb8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = study.trials_dataframe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
