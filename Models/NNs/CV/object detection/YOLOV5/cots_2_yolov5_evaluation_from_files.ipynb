{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## ðŸ“’ inferecne Notebooks:\n* Train: [Great-Barrier-Reef: YOLOv5 [train] ðŸŒŠ](https://www.kaggle.com/awsaf49/great-barrier-reef-yolov5-train)\n* Infer: [Great-Barrier-Reef: YOLOv5 [infer] ðŸŒŠ](https://www.kaggle.com/awsaf49/great-barrier-reef-yolov5-infer)\n* F2 score : [competition metric implementation](https://www.kaggle.com/bamps53/competition-metric-implementation)","metadata":{}},{"cell_type":"markdown","source":"## Import Library","metadata":{}},{"cell_type":"code","source":"from itertools import groupby\nimport numpy as np\nfrom tqdm.notebook import tqdm\ntqdm.pandas()\nimport pandas as pd\nimport os\nimport pickle\nimport cv2\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\n# import cupy as cp\nimport ast\nimport glob\n\nimport shutil\nimport sys\nsys.path.append('../input/tensorflow-great-barrier-reef')\n\nfrom joblib import Parallel, delayed\n\nfrom IPython.display import display, HTML\n\nfrom matplotlib import animation, rc\nrc('animation', html='jshtml')\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:44:07.332569Z","iopub.execute_input":"2022-02-13T14:44:07.33282Z","iopub.status.idle":"2022-02-13T14:44:07.742898Z","shell.execute_reply.started":"2022-02-13T14:44:07.332748Z","shell.execute_reply":"2022-02-13T14:44:07.742195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define model weight, validation images, labels","metadata":{}},{"cell_type":"code","source":"VAL_TXT = '/kaggle/input/yolo-val-conf/val.txt'\nTRAIN_TXT = '/kaggle/input/yolo-val-conf/train.txt'","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:44:07.744464Z","iopub.execute_input":"2022-02-13T14:44:07.744786Z","iopub.status.idle":"2022-02-13T14:44:07.748668Z","shell.execute_reply.started":"2022-02-13T14:44:07.744748Z","shell.execute_reply":"2022-02-13T14:44:07.747912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Make images, labels directory on /kaggle\nrefer to https://www.kaggle.com/awsaf49/great-barrier-reef-yolov5-train","metadata":{}},{"cell_type":"code","source":"FOLD = 2\n\nROOT_DIR  = '/kaggle/input/tensorflow-great-barrier-reef'\nIMAGE_DIR = f'/kaggle/working/yolo_data/fold{FOLD}/images' # directory to save images\nLABEL_DIR = f'/kaggle/working/yolo_data/fold{FOLD}/labels' # directory to save labels\n!mkdir -p {IMAGE_DIR}\n!mkdir -p {LABEL_DIR}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:44:07.749937Z","iopub.execute_input":"2022-02-13T14:44:07.750193Z","iopub.status.idle":"2022-02-13T14:44:09.060781Z","shell.execute_reply.started":"2022-02-13T14:44:07.75016Z","shell.execute_reply":"2022-02-13T14:44:09.059873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_path(row):\n    row['old_image_path'] = f'{ROOT_DIR}/train_images/video_{row.video_id}/{row.video_frame}.jpg'\n    row['image_path'] = f'{IMAGE_DIR}/video_{row.video_id}_{row.video_frame}.jpg'\n    row['label_path'] = f'{LABEL_DIR}/video_{row.video_id}_{row.video_frame}.txt'\n    return row","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:44:09.064047Z","iopub.execute_input":"2022-02-13T14:44:09.064341Z","iopub.status.idle":"2022-02-13T14:44:09.070877Z","shell.execute_reply.started":"2022-02-13T14:44:09.064307Z","shell.execute_reply":"2022-02-13T14:44:09.07008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Data\ndf = pd.read_csv(f'{ROOT_DIR}/train.csv')\ndf = df[df.video_id == FOLD]\ndf = df.progress_apply(get_path, axis=1)\ndf['annotations'] = df['annotations'].progress_apply(lambda x: ast.literal_eval(x))\ndf.head(2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:44:09.072381Z","iopub.execute_input":"2022-02-13T14:44:09.072917Z","iopub.status.idle":"2022-02-13T14:44:23.221209Z","shell.execute_reply.started":"2022-02-13T14:44:09.072881Z","shell.execute_reply":"2022-02-13T14:44:23.220391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['num_bbox'] = df['annotations'].progress_apply(lambda x: len(x))\ndata = (df.num_bbox>0).value_counts(normalize=True)*100\nprint(f\"No BBox: {data[0]:0.2f}% | With BBox: {data[1]:0.2f}%\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:44:23.222659Z","iopub.execute_input":"2022-02-13T14:44:23.222918Z","iopub.status.idle":"2022-02-13T14:44:23.286111Z","shell.execute_reply.started":"2022-02-13T14:44:23.222883Z","shell.execute_reply":"2022-02-13T14:44:23.284308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_copy(path):\n    data = path.split('/')\n    filename = data[-1]\n    video_id = data[-2]\n    new_path = os.path.join(IMAGE_DIR,f'{video_id}_{filename}')\n    shutil.copy(path, new_path)\n    return","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-13T14:44:23.287343Z","iopub.execute_input":"2022-02-13T14:44:23.287725Z","iopub.status.idle":"2022-02-13T14:44:23.293141Z","shell.execute_reply.started":"2022-02-13T14:44:23.28769Z","shell.execute_reply":"2022-02-13T14:44:23.292167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_image_paths = list()\n\ndef make_copy(path):\n    data = path.split('/')\n    filename = data[-1]\n    video_id = data[-2]\n    new_path = os.path.join(IMAGE_DIR,f'{video_id}_{filename}')\n    new_image_paths.append(new_path)\n    shutil.copy(path, new_path)\n    return\n\nimage_paths = df.old_image_path.tolist()\n_ = Parallel(n_jobs=-1, backend='threading')(delayed(make_copy)(path) for path in tqdm(image_paths))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:44:23.294525Z","iopub.execute_input":"2022-02-13T14:44:23.295103Z","iopub.status.idle":"2022-02-13T14:45:16.668824Z","shell.execute_reply.started":"2022-02-13T14:44:23.295057Z","shell.execute_reply":"2022-02-13T14:45:16.668078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/val.txt', 'w+') as f:\n    for item in new_image_paths:\n        f.write(f\"{item}\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:45:16.669963Z","iopub.execute_input":"2022-02-13T14:45:16.671926Z","iopub.status.idle":"2022-02-13T14:45:16.684643Z","shell.execute_reply.started":"2022-02-13T14:45:16.671893Z","shell.execute_reply":"2022-02-13T14:45:16.684066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def voc2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    voc  => [x1, y1, x2, y1]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]/ image_height\n    \n    w = bboxes[..., 2] - bboxes[..., 0]\n    h = bboxes[..., 3] - bboxes[..., 1]\n    \n    print(img_name)\n    bboxes[..., 0] = bboxes[..., 0] + w/2\n    bboxes[..., 1] = bboxes[..., 1] + h/2\n    bboxes[..., 2] = w\n    bboxes[..., 3] = h\n    \n    return bboxes\n\ndef yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n    \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n    \n    return bboxes\n\ndef coco2yolo(image_height, image_width, bboxes):\n    \"\"\"\n    coco => [xmin, ymin, w, h]\n    yolo => [xmid, ymid, w, h] (normalized)\n    \"\"\"\n    \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # normolizinig\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]/ image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]/ image_height\n    \n    # converstion (xmin, ymin) => (xmid, ymid)\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\ndef yolo2coco(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    coco => [xmin, ymin, w, h]\n    \n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n    \n    # denormalizing\n    bboxes[..., [0, 2]]= bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]]= bboxes[..., [1, 3]]* image_height\n    \n    # converstion (xmid, ymid) => (xmin, ymin) \n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    \n    return bboxes\n\n\ndef load_image(image_path):\n    return cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n\n\ndef plot_one_box(x, img, color=None, label=None, line_thickness=None):\n    # Plots one bounding box on image img\n    tl = line_thickness or round(0.002 * (img.shape[0] + img.shape[1]) / 2) + 1  # line/font thickness\n    color = color or [random.randint(0, 255) for _ in range(3)]\n    c1, c2 = (int(x[0]), int(x[1])), (int(x[2]), int(x[3]))\n    cv2.rectangle(img, c1, c2, color, thickness=tl, lineType=cv2.LINE_AA)\n    if label:\n        tf = max(tl - 1, 1)  # font thickness\n        t_size = cv2.getTextSize(label, 0, fontScale=tl / 3, thickness=tf)[0]\n        c2 = c1[0] + t_size[0], c1[1] - t_size[1] - 3\n        cv2.rectangle(img, c1, c2, color, -1, cv2.LINE_AA)  # filled\n        cv2.putText(img, label, (c1[0], c1[1] - 2), 0, tl / 3, [225, 255, 255], thickness=tf, lineType=cv2.LINE_AA)\n\ndef draw_bboxes(img, bboxes, classes, class_ids, colors = None, show_classes = None, bbox_format = 'yolo', class_name = False, line_thickness = 2):  \n     \n    image = img.copy()\n    show_classes = classes if show_classes is None else show_classes\n    colors = (0, 255 ,0) if colors is None else colors\n    \n    if bbox_format == 'yolo':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:\n            \n                x1 = round(float(bbox[0])*image.shape[1])\n                y1 = round(float(bbox[1])*image.shape[0])\n                w  = round(float(bbox[2])*image.shape[1]/2) #w/2 \n                h  = round(float(bbox[3])*image.shape[0]/2)\n\n                voc_bbox = (x1-w, y1-h, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(get_label(cls)),\n                             line_thickness = line_thickness)\n            \n    elif bbox_format == 'coco':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes:            \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                w  = int(round(bbox[2]))\n                h  = int(round(bbox[3]))\n\n                voc_bbox = (x1, y1, x1+w, y1+h)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n\n    elif bbox_format == 'voc_pascal':\n        \n        for idx in range(len(bboxes)):  \n            \n            bbox  = bboxes[idx]\n            cls   = classes[idx]\n            cls_id = class_ids[idx]\n            color = colors[cls_id] if type(colors) is list else colors\n            \n            if cls in show_classes: \n                x1 = int(round(bbox[0]))\n                y1 = int(round(bbox[1]))\n                x2 = int(round(bbox[2]))\n                y2 = int(round(bbox[3]))\n                voc_bbox = (x1, y1, x2, y2)\n                plot_one_box(voc_bbox, \n                             image,\n                             color = color,\n                             label = cls if class_name else str(cls_id),\n                             line_thickness = line_thickness)\n    else:\n        raise ValueError('wrong bbox format')\n\n    return image\n\ndef get_bbox(annots):\n    bboxes = [list(annot.values()) for annot in annots]\n    return bboxes\n\ndef get_imgsize(row):\n    row['width'], row['height'] = imagesize.get(row['image_path'])\n    return row\n\n\n# https://www.kaggle.com/diegoalejogm/great-barrier-reefs-eda-with-animations\ndef create_animation(ims):\n    fig = plt.figure(figsize=(16, 12))\n    plt.axis('off')\n    im = plt.imshow(ims[0])\n\n    def animate_func(i):\n        im.set_array(ims[i])\n        return [im]\n\n    return animation.FuncAnimation(fig, animate_func, frames = len(ims), interval = 1000//12)\n\nnp.random.seed(32)\ncolors = [(np.random.randint(255), np.random.randint(255), np.random.randint(255))\\\n          for idx in range(1)]","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:45:16.687627Z","iopub.execute_input":"2022-02-13T14:45:16.687874Z","iopub.status.idle":"2022-02-13T14:45:16.730334Z","shell.execute_reply.started":"2022-02-13T14:45:16.687843Z","shell.execute_reply":"2022-02-13T14:45:16.72953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['bboxes'] = df.annotations.progress_apply(get_bbox)\ndf.head(2)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:45:16.732958Z","iopub.execute_input":"2022-02-13T14:45:16.733172Z","iopub.status.idle":"2022-02-13T14:45:16.80239Z","shell.execute_reply.started":"2022-02-13T14:45:16.733148Z","shell.execute_reply":"2022-02-13T14:45:16.801758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['width']  = 1280\ndf['height'] = 720\ndisplay(df.head(2))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:45:16.803628Z","iopub.execute_input":"2022-02-13T14:45:16.804071Z","iopub.status.idle":"2022-02-13T14:45:16.822177Z","shell.execute_reply.started":"2022-02-13T14:45:16.804036Z","shell.execute_reply":"2022-02-13T14:45:16.821559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = 0\nall_bboxes = []\nfor row_idx in tqdm(range(df.shape[0])):\n    row = df.iloc[row_idx]\n    image_height = row.height\n    image_width  = row.width\n    bboxes_coco  = np.array(row.bboxes).astype(np.float32).copy()\n    num_bbox     = len(bboxes_coco)\n    names        = ['cots']*num_bbox\n    labels       = [0]*num_bbox\n    ## Create Annotation(YOLO)\n    with open(row.label_path, 'w') as f:\n        if num_bbox<1:\n            annot = ''\n            f.write(annot)\n            cnt+=1\n            continue\n        bboxes_yolo  = coco2yolo(image_height, image_width, bboxes_coco)\n        bboxes_yolo  = np.clip(bboxes_yolo, 0, 1)\n        all_bboxes.extend(bboxes_yolo)\n        for bbox_idx in range(len(bboxes_yolo)):\n            annot = [str(labels[bbox_idx])]+ list(bboxes_yolo[bbox_idx].astype(str))+(['\\n'] if num_bbox!=(bbox_idx+1) else [''])\n            annot = ' '.join(annot)\n            annot = annot.strip(' ')\n            f.write(annot)\nprint('Missing:',cnt)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-13T14:45:16.823366Z","iopub.execute_input":"2022-02-13T14:45:16.823801Z","iopub.status.idle":"2022-02-13T14:45:19.94748Z","shell.execute_reply.started":"2022-02-13T14:45:16.823766Z","shell.execute_reply":"2022-02-13T14:45:19.946687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# images, labels folder check\nassert os.path.exists(IMAGE_DIR)\nassert os.path.exists(LABEL_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:45:19.948912Z","iopub.execute_input":"2022-02-13T14:45:19.949309Z","iopub.status.idle":"2022-02-13T14:45:19.956297Z","shell.execute_reply.started":"2022-02-13T14:45:19.949271Z","shell.execute_reply":"2022-02-13T14:45:19.95567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## YOLOV5 install","metadata":{}},{"cell_type":"code","source":"%cd /kaggle/working\n!rm -r /kaggle/working/yolov5\n!git clone https://github.com/ultralytics/yolov5 # clone\n%cd yolov5\n%pip install -qr requirements.txt  # install\n\nfrom yolov5 import utils\ndisplay = utils.notebook_init()  # check","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:45:19.957425Z","iopub.execute_input":"2022-02-13T14:45:19.957815Z","iopub.status.idle":"2022-02-13T14:45:37.774829Z","shell.execute_reply.started":"2022-02-13T14:45:19.95778Z","shell.execute_reply":"2022-02-13T14:45:37.774004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run YOLOV5 model in validation images ","metadata":{}},{"cell_type":"code","source":"# move files to /kaggle/working\n!cp /kaggle/input/reef-baseline-fold12/l6_3600_uflip_vm5_f12_up/f1/best.pt /kaggle/working/\n# !cp /kaggle/input/yolo-val-conf/train.txt /kaggle/working/\n#!cp /kaggle/input/yolo-val-conf/val.txt /kaggle/working/\n!cp /kaggle/input/yolo-val-conf/bgr.yaml /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:45:37.776809Z","iopub.execute_input":"2022-02-13T14:45:37.77727Z","iopub.status.idle":"2022-02-13T14:45:39.629571Z","shell.execute_reply.started":"2022-02-13T14:45:37.777226Z","shell.execute_reply":"2022-02-13T14:45:39.628597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:45:39.631175Z","iopub.execute_input":"2022-02-13T14:45:39.631457Z","iopub.status.idle":"2022-02-13T14:45:39.639861Z","shell.execute_reply.started":"2022-02-13T14:45:39.63142Z","shell.execute_reply":"2022-02-13T14:45:39.639002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python  val.py --data ../bgr.yaml\\\n    --weights ../best.pt\\\n    --imgsz 3200\\\n    --batch 8\\\n    --conf-thres 0.5\\\n    --iou-thres 0.4\\\n    --save-txt\\\n    --save-conf\\\n    --exist-ok","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:45:39.641277Z","iopub.execute_input":"2022-02-13T14:45:39.641802Z","iopub.status.idle":"2022-02-13T14:58:08.8976Z","shell.execute_reply.started":"2022-02-13T14:45:39.641766Z","shell.execute_reply":"2022-02-13T14:58:08.89674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check how predicted bounding box is created","metadata":{}},{"cell_type":"code","source":"# val bbox result directory\nPRD_BBOX_DIR = '/kaggle/working/yolov5/runs/val/exp/labels/'\nprint(f'made bounding box of {len(os.listdir(PRD_BBOX_DIR))} images in validation set ')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:58:08.901348Z","iopub.execute_input":"2022-02-13T14:58:08.901606Z","iopub.status.idle":"2022-02-13T14:58:08.908431Z","shell.execute_reply.started":"2022-02-13T14:58:08.901564Z","shell.execute_reply":"2022-02-13T14:58:08.907726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### why predicted bounding box txt file for some images doesn't exist?","metadata":{}},{"cell_type":"code","source":"val_images = []\nwith open('/kaggle/working/val.txt', 'r') as f:\n    while True:\n        r = f.readline().rstrip()\n        if not r:\n            break\n        val_images.append(os.path.basename(r))\nprint(f'{len(val_images)} image in validation set')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:58:08.909562Z","iopub.execute_input":"2022-02-13T14:58:08.911006Z","iopub.status.idle":"2022-02-13T14:58:08.942397Z","shell.execute_reply.started":"2022-02-13T14:58:08.910972Z","shell.execute_reply":"2022-02-13T14:58:08.941677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_processed_images = val_images.copy()\nfor file in os.listdir(PRD_BBOX_DIR):\n    img_name = file[:-4]+'.jpg'\n    if img_name in val_images:\n        not_processed_images.remove(img_name)\nprint(f\"yolov5 model doesn't create bounding box for {len(not_processed_images)} images\")","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:58:08.943481Z","iopub.execute_input":"2022-02-13T14:58:08.943797Z","iopub.status.idle":"2022-02-13T14:58:09.090047Z","shell.execute_reply.started":"2022-02-13T14:58:08.943761Z","shell.execute_reply":"2022-02-13T14:58:09.08936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model didn't detect starfish in \"not_processed_images\" - it will be calculated as False Negative(FN)\n\nrun code to know that there exist ground truth bounding boxs in \"not_processed_images\"","metadata":{}},{"cell_type":"markdown","source":"## Calculate F2 score on validation set\nreference : [competition metric implementation](https://www.kaggle.com/bamps53/competition-metric-implementation)","metadata":{}},{"cell_type":"code","source":"def calc_iou(bboxes1, bboxes2, bbox_mode='xywh'):\n    assert len(bboxes1.shape) == 2 and bboxes1.shape[1] == 4\n    assert len(bboxes2.shape) == 2 and bboxes2.shape[1] == 4\n    \n    bboxes1 = bboxes1.copy()\n    bboxes2 = bboxes2.copy()\n    \n    if bbox_mode == 'xywh':\n        bboxes1[:, 2:] += bboxes1[:, :2]\n        bboxes2[:, 2:] += bboxes2[:, :2]\n\n    x11, y11, x12, y12 = np.split(bboxes1, 4, axis=1)\n    x21, y21, x22, y22 = np.split(bboxes2, 4, axis=1)\n    xA = np.maximum(x11, np.transpose(x21))\n    yA = np.maximum(y11, np.transpose(y21))\n    xB = np.minimum(x12, np.transpose(x22))\n    yB = np.minimum(y12, np.transpose(y22))\n    interArea = np.maximum((xB - xA + 1), 0) * np.maximum((yB - yA + 1), 0)\n    boxAArea = (x12 - x11 + 1) * (y12 - y11 + 1)\n    boxBArea = (x22 - x21 + 1) * (y22 - y21 + 1)\n    iou = interArea / (boxAArea + np.transpose(boxBArea) - interArea)\n    return iou\n\ndef f_beta(tp, fp, fn, beta=2):\n    return (1+beta**2)*tp / ((1+beta**2)*tp + beta**2*fn+fp)\n\ndef calc_is_correct_at_iou_th(gt_bboxes, pred_bboxes, iou_th, verbose=False):\n    gt_bboxes = gt_bboxes.copy()\n    pred_bboxes = pred_bboxes.copy()\n    \n    tp = 0\n    fp = 0\n    for k, pred_bbox in enumerate(pred_bboxes): # fixed in ver.7\n        ious = calc_iou(gt_bboxes, pred_bbox[None, 1:])\n        max_iou = ious.max()\n        if max_iou > iou_th:\n            tp += 1\n            gt_bboxes = np.delete(gt_bboxes, ious.argmax(), axis=0)\n        else:\n            fp += 1\n        if len(gt_bboxes) == 0:\n            fp += len(pred_bboxes) - (k + 1) # fix in ver.7\n            break\n\n    fn = len(gt_bboxes)\n    return tp, fp, fn\n\ndef calc_is_correct(gt_bboxes, pred_bboxes):\n    \"\"\"\n    gt_bboxes: (N, 4) np.array in xywh format\n    pred_bboxes: (N, 5) np.array in conf+xywh format\n    \"\"\"\n    if len(gt_bboxes) == 0 and len(pred_bboxes) == 0:\n        tps, fps, fns = 0, 0, 0\n        return tps, fps, fns\n    \n    elif len(gt_bboxes) == 0:\n        tps, fps, fns = 0, len(pred_bboxes)*11, 0\n        return tps, fps, fns\n    \n    elif len(pred_bboxes) == 0:\n        tps, fps, fns = 0, 0, len(gt_bboxes)*11\n        return tps, fps, fns\n    \n    pred_bboxes = pred_bboxes[pred_bboxes[:,0].argsort()[::-1]] # sort by conf\n    \n    tps, fps, fns = 0, 0, 0\n    for iou_th in np.arange(0.3, 0.85, 0.05):\n        tp, fp, fn = calc_is_correct_at_iou_th(gt_bboxes, pred_bboxes, iou_th)\n        tps += tp\n        fps += fp\n        fns += fn\n    return tps, fps, fns\n\ndef calc_f2_score(gt_bboxes_list, pred_bboxes_list, verbose=False):\n    \"\"\"\n    gt_bboxes_list: list of (N, 4) np.array in xywh format\n    pred_bboxes_list: list of (N, 5) np.array in conf+xywh format\n    \"\"\"\n    tps, fps, fns = 0, 0, 0\n    for gt_bboxes, pred_bboxes in zip(gt_bboxes_list, pred_bboxes_list):\n        tp, fp, fn = calc_is_correct(gt_bboxes, pred_bboxes)\n        tps += tp\n        fps += fp\n        fns += fn\n        if verbose:\n            num_gt = len(gt_bboxes)\n            num_pred = len(pred_bboxes)\n            print(f'num_gt:{num_gt:<3} num_pred:{num_pred:<3} tp:{tp:<3} fp:{fp:<3} fn:{fn:<3}')\n    return f_beta(tps, fps, fns, beta=2)","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:58:09.091396Z","iopub.execute_input":"2022-02-13T14:58:09.091712Z","iopub.status.idle":"2022-02-13T14:58:09.113823Z","shell.execute_reply.started":"2022-02-13T14:58:09.091675Z","shell.execute_reply":"2022-02-13T14:58:09.113071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gt_bboxs_list, prd_bboxs_list = [], []\ncount = 0\nfor image_file in val_images:\n    txt_name = image_file[:-4]+'.txt'\n    gt_bboxs = []\n    prd_bboxs = []\n    with open(LABEL_DIR+'/'+txt_name, 'r') as f:\n        while True:\n            r = f.readline().rstrip()\n            if not r:\n                break\n            r = r.split()[1:]\n            bbox = np.array(list(map(float, r)))\n            gt_bboxs.append(bbox)\n    if os.path.exists(PRD_BBOX_DIR+txt_name):\n        with open(PRD_BBOX_DIR+txt_name, 'r') as f:\n            while True:\n                r = f.readline().rstrip()\n                if not r:\n                    break\n                r = r.split()[1:]\n                r = [r[4], *r[:4]]\n                bbox = np.array(list(map(float, r)))\n                prd_bboxs.append(bbox)\n    gt_bboxs, prd_bboxs = np.array(gt_bboxs), np.array(prd_bboxs)\n    gt_bboxs_list.append(gt_bboxs)\n    prd_bboxs_list.append(prd_bboxs)\n    count += 1\nprint(f'{count} bound boxs appended to list')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-13T14:58:09.115208Z","iopub.execute_input":"2022-02-13T14:58:09.115481Z","iopub.status.idle":"2022-02-13T14:58:09.622943Z","shell.execute_reply.started":"2022-02-13T14:58:09.115444Z","shell.execute_reply":"2022-02-13T14:58:09.621172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = calc_f2_score(gt_bboxs_list, prd_bboxs_list, verbose=True)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-02-13T14:58:09.625737Z","iopub.execute_input":"2022-02-13T14:58:09.626618Z","iopub.status.idle":"2022-02-13T14:58:14.351709Z","shell.execute_reply.started":"2022-02-13T14:58:09.626541Z","shell.execute_reply":"2022-02-13T14:58:14.351052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'f2 score for validation set is {score}')","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:58:14.354497Z","iopub.execute_input":"2022-02-13T14:58:14.354695Z","iopub.status.idle":"2022-02-13T14:58:14.360741Z","shell.execute_reply.started":"2022-02-13T14:58:14.354668Z","shell.execute_reply":"2022-02-13T14:58:14.359999Z"},"trusted":true},"execution_count":null,"outputs":[]}]}