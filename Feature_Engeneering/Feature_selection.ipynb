{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4b8aa3",
   "metadata": {},
   "source": [
    "# Permutation feature selection + LGBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de43236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits, BaseShuffleSplit, _validate_shuffle_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import _num_samples, check_array\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "\n",
    "import eli5\n",
    "from IPython.display import display\n",
    "from eli5.permutation_importance import get_score_importances\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from shaphypetune import BoostBoruta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from colorama import Style, Fore\n",
    "\n",
    "palette = ['#302c36', '#037d97', '#E4591E', '#C09741',\n",
    "           '#EC5B6D', '#90A6B1', '#6ca957', '#D8E3E2']\n",
    "\n",
    "blk = Style.BRIGHT + Fore.BLACK\n",
    "red = Style.BRIGHT + Fore.RED\n",
    "blu = Style.BRIGHT + Fore.BLUE\n",
    "res = Style.RESET_ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33a90a5",
   "metadata": {},
   "source": [
    "# Set all features combinations (brute force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3256ea9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = train_df.drop(['f_1', 'target'], axis=1).columns\n",
    "generated_features = pd.DataFrame()\n",
    "\n",
    "# with all of these features usually will work too long, so try to comment some of them \n",
    "# and select features separately\n",
    "for fe_a, fe_b in itertools.combinations(features, 2):\n",
    "\n",
    "    generated_features[f'{fe_a}+{fe_b}']   = train_df[fe_a] + train_df[fe_b]\n",
    "    generated_features[f'{fe_a}-{fe_b}']   = train_df[fe_a] - train_df[fe_b] \n",
    "    generated_features[f'{fe_a}*{fe_b}']   = train_df[fe_a] * train_df[fe_b]\n",
    "    generated_features[f'{fe_a}/{fe_b}']   = train_df[fe_a] / train_df[fe_b]\n",
    "\n",
    "    generated_features[f'{fe_a}*{fe_b}_2'] = train_df[fe_a] * train_df[fe_b].pow(2)\n",
    "    generated_features[f'{fe_a}_2*{fe_b}'] = train_df[fe_a].pow(2) * train_df[fe_b]\n",
    "    generated_features[f'{fe_a}_2']        = rain_df[fe_a].pow(2)\n",
    "    generated_features[f'{fe_b}_2']        = train_df[fe_b].pow(2)\n",
    "\n",
    "    generated_features[f'{fe_a}_05'] = train_df[fe_a].pow(0.5)\n",
    "    generated_features[f'{fe_b}_05'] = train_df[fe_b].pow(0.5)\n",
    "    generated_features[f'{fe_a}*{fe_b}_05'] = train_df[fe_a] * train_df[fe_b].pow(0.5)\n",
    "    generated_features[f'{fe_a}_05*{fe_b}'] = train_df[fe_a].pow(0.5) * train_df[fe_b]\n",
    "    \n",
    "    generated_features[f'{fe_a}_log'] = np.log(train_df[fe_a])\n",
    "    generated_features[f'{fe_b}_log'] = np.log(train_df[fe_b])\n",
    "    generated_features[f'{fe_a}*{fe_b}_log'] = train_df[fe_a] * np.log(train_df[fe_b])\n",
    "    generated_features[f'{fe_a}_log*{fe_b}'] = np.log(train_df[fe_a]) * train_df[fe_b]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e5704a",
   "metadata": {},
   "source": [
    "# Nested CV + LGBM importance + Permutation importance + Boruta SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561b809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG:\n",
    "    n_repeats = 4\n",
    "    n_folds = 5\n",
    "\n",
    "params = {\n",
    "        'boosting_type':'goss',\n",
    "        'learning_rate': 0.06733232950390658, \n",
    "        'n_estimators': 50000, \n",
    "        'early_stopping_round' : 100, \n",
    "        'subsample' : 0.6970532011679706,\n",
    "        'colsample_bytree': 0.6055755840633003,\n",
    "        'num_leaves': 6,\n",
    "        'class_weight': 'balanced',\n",
    "        'metric': 'none', \n",
    "        'is_unbalance': True, \n",
    "        'random_state': 8062023,\n",
    "        'feature_fraction_seed': 8062023,\n",
    "        'bagging_seed': 8062023,\n",
    "        'max_depth': 8,\n",
    "        'reg_alpha': 0.08866046540248787,  \n",
    "        'reg_lambda': 1.0245261859148395e-06,\n",
    "        'importance_type': 'gain'\n",
    "        }\n",
    "\n",
    "def lgbm_tuning(features, permut=False, boruta=False):\n",
    "    metric = balanced_log_loss\n",
    "    eval_results_ = {}\n",
    "\n",
    "    outer_cv_score = [] # store all cv scores of outer loop inference\n",
    "    inner_cv_score = [] # store all cv scores of inner loop training\n",
    "\n",
    "    perm_df_ = pd.DataFrame()\n",
    "    feature_importances_ = pd.DataFrame()\n",
    "    boruta_df_ = pd.DataFrame()\n",
    "    \n",
    "    for i in range(CFG.n_repeats):\n",
    "        print(f'Repeat {blu}#{i+1}')\n",
    "        \n",
    "        kf = MultilabelStratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=8062023+i)\n",
    "\n",
    "        # Stratify based on Class and Alpha (3 types of conditions)\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X=train_df[features], y=greeks.iloc[:,1:3]), start = 1): \n",
    "            X, y = train_df[features], train_df.Class\n",
    "#             X, y = generated_features_train, train_df.Class\n",
    "            # Split the dataset according to the fold indexes.\n",
    "            X_train = X.iloc[train_idx]\n",
    "            X_val = X.iloc[val_idx]\n",
    "            y_train = y.iloc[train_idx]\n",
    "            y_val = y.iloc[val_idx]\n",
    "\n",
    "            # 20% hold-out set\n",
    "            X_holdout, y_holdout = X_val, y_val\n",
    "\n",
    "            # Create an oof array for inner loop\n",
    "            oof_inner = np.zeros(len(X_train))\n",
    "\n",
    "            X_train = X_train.reset_index(drop=True)\n",
    "            y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "            cv = StratifiedKFold(n_splits=CFG.n_folds, shuffle=True, random_state=8062023+i) # Use stratifiedKfold to make life easier\n",
    "\n",
    "            X_outer, y_outer = X_train, y_train\n",
    "\n",
    "            models_ = [] # Used to store models trained in the inner loop.\n",
    "\n",
    "            print(f\"Outer Loop fold {fold}, Inner Loop Training with {blu}{X_train.shape[0]}{res} samples, {blu}{X_train.shape[1]}{res} features, seed = {blu}{8602023}{res}\")\n",
    "\n",
    "            for fold, (train_idx, val_idx) in enumerate(cv.split(X=X_train, y=y_train), start = 1):\n",
    "                # Split the dataset according to the fold indexes.\n",
    "                X_train = X_outer.iloc[train_idx]\n",
    "                X_val = X_outer.iloc[val_idx]\n",
    "                y_train = y_outer.iloc[train_idx]\n",
    "                y_val = y_outer.iloc[val_idx]\n",
    "\n",
    "                eval_results_[fold]= {}\n",
    "\n",
    "                clf = lgb.LGBMClassifier(**params)\n",
    "                clf.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "                        eval_metric='logloss', \n",
    "                        early_stopping_rounds=300, verbose=-1)\n",
    "\n",
    "                models_.append(clf)\n",
    "\n",
    "                val_preds = clf.predict_proba(X_val)[:,1]\n",
    "                oof_inner[val_idx] = val_preds\n",
    "\n",
    "                val_score = metric(y_val, val_preds)\n",
    "                best_iter = clf.best_iteration_\n",
    "\n",
    "                print(f'Fold: {blu}{fold:>3}{res}| {metric.__name__}: {blu}{val_score:.5f}{res}'\n",
    "                      f' | Best iteration: {blu}{best_iter:>4}{res}')\n",
    "\n",
    "                # permutation importance\n",
    "                if permut:\n",
    "                    perm = PermutationImportance(clf, scoring=None, n_iter=1, \n",
    "                                                 random_state=42, cv=None, refit=False).fit(X_val, y_val)\n",
    "\n",
    "                    perm_importance_df = pd.DataFrame({'importance': perm.feature_importances_}, \n",
    "                                                       index=X_val.columns).sort_index()\n",
    "\n",
    "                    if perm_df_.shape[0] == 0:\n",
    "                        perm_df_ = perm_importance_df.copy()\n",
    "                    else:\n",
    "                        perm_df_ += perm_importance_df\n",
    "\n",
    "                # tree feature importance\n",
    "                f_i = pd.DataFrame(sorted(zip(clf.feature_importances_, X.columns), \n",
    "                                                  reverse=True, key=lambda x: x[1]), \n",
    "                                   columns=['Value','Feature'])\n",
    "\n",
    "                if feature_importances_.shape[0] == 0:\n",
    "                    feature_importances_ = f_i.copy()\n",
    "                else:\n",
    "\n",
    "                    feature_importances_['Value'] += f_i['Value']\n",
    "                    \n",
    "                # BORUTA importance\n",
    "                if boruta:\n",
    "                    model = BoostBoruta(clf, importance_type='shap_importances', train_importance=False)\n",
    "                    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)], \n",
    "                              eval_metric=bll_metric, early_stopping_rounds=300, verbose=-1)\n",
    "                    \n",
    "                    boruta_importance_df = pd.DataFrame({'importance': model.ranking_}, \n",
    "                                                         index=X_train.columns).sort_index()\n",
    "                    if boruta_df_.shape[0] == 0:\n",
    "                        boruta_df_ = boruta_importance_df.copy()\n",
    "                    else:\n",
    "                        boruta_df_ += boruta_importance_df\n",
    "\n",
    "            mean_cv_score = metric(y_outer, oof_inner)\n",
    "            print(f'{red} Inner CV score: {res} {metric.__name__}: {red}{mean_cv_score:.5f}{res}')\n",
    "            print(f'{\"*\" * 50}\\n')\n",
    "            inner_cv_score.append(mean_cv_score)\n",
    "\n",
    "            # infer holdout data using 5-fold model trained in inner loop\n",
    "            preds = np.zeros(len(X_holdout))\n",
    "            for model in models_:\n",
    "                preds += model.predict_proba(X_holdout)[:,1]\n",
    "            preds = preds / len(models_)\n",
    "            cv_score = metric(y_holdout, preds)\n",
    "            print(f'{red} Outer Holdout score: {res} {metric.__name__}: {red}{cv_score:.5f}{res}')\n",
    "            print(f'{\"*\" * 50}\\n')\n",
    "            outer_cv_score.append(cv_score)\n",
    "\n",
    "    print(f'{red} Inner CV avg score: {res} {metric.__name__}: {red}{np.mean(inner_cv_score):.5f}{res}')\n",
    "    print(f'{\"*\" * 50}\\n')\n",
    "\n",
    "    print(f'{red} Outer Holdout avg score: {res} {metric.__name__}: {red}{np.mean(outer_cv_score):.5f}{res}')\n",
    "    print(f'{\"*\" * 50}\\n')\n",
    "    \n",
    "    if permut:\n",
    "        perm_df_ = perm_df_.sort_values('importance', ascending=False)\n",
    "        \n",
    "    if boruta:\n",
    "        boruta_df_ = boruta_df_.sort_values('importance')\n",
    "                                    \n",
    "    feature_importances_ = feature_importances_.sort_values('Value', ascending=False)\n",
    "    \n",
    "    return perm_df_, feature_importances_, boruta_df_, np.mean(inner_cv_score), np.mean(outer_cv_score)\n",
    "\n",
    "perm_df_, feature_importances_, boruta_df_, inner_cv_score, outer_cv_score = lgbm_tuning(features, permut=False, boruta=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00ed9d89",
   "metadata": {},
   "source": [
    "# SelectKBest Method from SKLearn for Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ea306b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "threshold = 0.1\n",
    "t_score = 5\n",
    "\n",
    "# Initiate the SelectKBest function\n",
    "# For regression tasks: f_regression, mutual_info_regression\n",
    "# For classification tasks: chi2, f_classif, mutual_info_classif\n",
    "fs = SelectKBest(score_func=f_classif, k=len(train.columns))\n",
    "\n",
    "# apply feature selection\n",
    "X_selected = fs.fit_transform(train, test.values)\n",
    "print('Befoe the SelectKBest = {}'.format(train.shape))\n",
    "\n",
    "new_features = [] # The list of features less than the p-values\n",
    "drop_features = [] # The list of features higher than the p-values\n",
    "\n",
    "for i in range(len(train.columns)):\n",
    "    print('Feature {}: {:.3f} with p-value {:.3f}'.format(train.columns[i], fs.scores_[i], fs.pvalues_[i]))\n",
    "    if fs.pvalues_[i] <= threshold and fs.scores_[i] >= t_score:\n",
    "        new_features.append(train.columns[i])\n",
    "    else:\n",
    "        drop_features.append(train.columns[i])\n",
    "\n",
    "X_selected_final =  pd.DataFrame(X_selected)\n",
    "X_selected_final.columns = train.columns\n",
    "#    print(X_selected_final.shape)\n",
    "X_selected_final = X_selected_final[new_features]\n",
    "#    print(X_selected_final.shape)\n",
    "\n",
    "print('=' * 30)\n",
    "print('After the SelectKBest = {}'.format(X_selected_final.shape))\n",
    "print('Drop-out Features = {}'.format(len(drop_features)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea1237c7",
   "metadata": {},
   "source": [
    "# Select features using Information Value (IV) and Weights of evidence (WoE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8c0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iv_woe(data, target, bins=10, show_woe=False):\n",
    "    \n",
    "    #Empty Dataframe\n",
    "    newDF,woeDF = pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    #Extract Column Names\n",
    "    cols = data.columns\n",
    "    \n",
    "    #Run WOE and IV on all the independent variables\n",
    "    for ivars in cols[~cols.isin([target])]:\n",
    "        if (data[ivars].dtype.kind in 'bifc') and (len(np.unique(data[ivars]))>10):\n",
    "            binned_x = pd.qcut(data[ivars], bins,  duplicates='drop')\n",
    "            d0 = pd.DataFrame({'x': binned_x, 'y': data[target]})\n",
    "        else:\n",
    "            d0 = pd.DataFrame({'x': data[ivars], 'y': data[target]})\n",
    "\n",
    "        \n",
    "        # Calculate the number of events in each group (bin)\n",
    "        d = d0.groupby(\"x\", as_index=False).agg({\"y\": [\"count\", \"sum\"]})\n",
    "        d.columns = ['Cutoff', 'N', 'Events']\n",
    "        \n",
    "        # Calculate % of events in each group.\n",
    "        d['% of Events'] = np.maximum(d['Events'], 0.5) / d['Events'].sum()\n",
    "\n",
    "        # Calculate the non events in each group.\n",
    "        d['Non-Events'] = d['N'] - d['Events']\n",
    "        # Calculate % of non events in each group.\n",
    "        d['% of Non-Events'] = np.maximum(d['Non-Events'], 0.5) / d['Non-Events'].sum()\n",
    "\n",
    "        # Calculate WOE by taking natural log of division of % of non-events and % of events\n",
    "        d['WoE'] = np.log(d['% of Events']/d['% of Non-Events'])\n",
    "        d['IV'] = d['WoE'] * (d['% of Events'] - d['% of Non-Events'])\n",
    "        d.insert(loc=0, column='Variable', value=ivars)\n",
    "        #print(\"Information value of \" + ivars + \" is \" + str(round(d['IV'].sum(),6)))\n",
    "        temp =pd.DataFrame({\"Variable\" : [ivars], \"IV\" : [d['IV'].sum()]}, columns = [\"Variable\", \"IV\"])\n",
    "        newDF=pd.concat([newDF,temp], axis=0)\n",
    "        woeDF=pd.concat([woeDF,d], axis=0)\n",
    "\n",
    "        #Show WOE Table\n",
    "        if show_woe == True:\n",
    "            print(d)\n",
    "    return newDF, woeDF\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
