{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1b2191eb",
   "metadata": {},
   "source": [
    "# Some useful presentations\n",
    "\n",
    "https://github.com/data-mining-in-action/DMIA_Sport_2019_Autumn/tree/master/lectures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64b24356",
   "metadata": {},
   "source": [
    "# Create dataset with all unique combinations of given columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37436d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "index_cols = ['shop_id', 'item_id', 'date_block_num']\n",
    "\n",
    "# For every month we create a grid from all shops/items combinations from that month\n",
    "grid = [] \n",
    "for block_num in df['date_block_num'].unique():\n",
    "    cur_shops = sales_train[sales_train['date_block_num']==block_num]['shop_id'].unique()\n",
    "    cur_items = sales_train[sales_train['date_block_num']==block_num]['item_id'].unique()\n",
    "    grid.append(np.array(list(product(*[cur_shops, cur_items, [block_num]])),dtype='int32'))\n",
    "\n",
    "#turn the grid into pandas dataframe\n",
    "grid = pd.DataFrame(np.vstack(grid), columns = index_cols, dtype=np.int32)\n",
    "\n",
    "#get aggregated values for (shop_id, item_id, month)\n",
    "gb = sales_train.groupby(index_cols, as_index=False).agg({'item_cnt_day': 'sum'})\n",
    "\n",
    "#join aggregated data to the grid\n",
    "all_data = pd.merge(grid, gb, how='left', on=index_cols).fillna(0)\n",
    "#sort the data\n",
    "all_data.sort_values(['date_block_num', 'shop_id', 'item_id'],inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be9d2ab5",
   "metadata": {},
   "source": [
    "# Add calendar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4e0e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import calendar\n",
    "import holidays\n",
    "import datetime\n",
    "\n",
    "date_blocks = pd.DataFrame(sales_train2.date_block_num.drop_duplicates())\n",
    "\n",
    "def add_month(col):\n",
    "    return int(divmod(col, 12)[1] + 1)\n",
    "\n",
    "def add_year(col):\n",
    "    return int(2013 + divmod(col+1, 12)[0])\n",
    "\n",
    "def add_year_month(row):\n",
    "    return f'{row.year}-{row.month}'\n",
    "\n",
    "def add_season(col):\n",
    "    if 0 < col <= 2 or col == 12:\n",
    "        return 'winter'\n",
    "    if 3 <= col < 6:\n",
    "        return 'spring'\n",
    "    if 6 <= col < 9:\n",
    "        return 'summer'\n",
    "    if 9 <= col < 12:\n",
    "        return 'autumn'\n",
    "    return np.nan\n",
    "\n",
    "# get number of holidays + weekend in each month    \n",
    "ru_holidays = []\n",
    "\n",
    "for date, name in sorted(holidays.RU(years=[2013, 2014, 2015]).items()):\n",
    "    ru_holidays.append(date)\n",
    "    \n",
    "def add_holidays_and_weekends(row):\n",
    "    busines_dates = pd.bdate_range(f\"{row.year}-{row.month}-01\", f\"{row.year}-{row.month}-{row.days_in_month}\")\n",
    "    busines_dates = [b for b in busines_dates if b not in ru_holidays]\n",
    "    return row.days_in_month - len(busines_dates)\n",
    "    \n",
    "def add_weeks_in_month(row):\n",
    "    for i in range(1, row.days_in_month+1):\n",
    "        d = datetime.datetime(row.year, row.month, i)\n",
    "        if d.day > d.weekday():\n",
    "            startdate = d\n",
    "            break\n",
    "    return ((datetime.datetime(row.year, row.month, row.days_in_month) - startdate).days) //7 + 1 \n",
    "    \n",
    "def create_calendar_features(data):\n",
    "    data['month'] = data.date_block_num.apply(add_month) \n",
    "    data['year'] = data.date_block_num.apply(add_year)\n",
    "    data['year_month'] = data.apply(add_year_month, axis=1)\n",
    "    data.year_month = pd.to_datetime(data.year_month, format='%Y-%m')\n",
    "    data['days_in_month'] = data.year_month.dt.daysinmonth\n",
    "    data['weeks_in_month'] = data.apply(add_weeks_in_month, axis=1)\n",
    "    data['season'] = data.month.apply(add_season)\n",
    "    data['holidays_and_weekends_in_month'] = data.apply(add_holidays_and_weekends, axis=1)\n",
    "\n",
    "\n",
    "create_calendar_features(date_blocks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f2fabf3",
   "metadata": {},
   "source": [
    "# Create group features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d00c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gr_feats(data):\n",
    "    # create aggregation feats for numeric features based on categorical ones\n",
    "    for cat_col in ['shop_id', 'item_category_id', 'city', 'item_id']:\n",
    "        for num_col in ['item_cnt_month', 'item_price']:\n",
    "            for n, f in [('mean', np.mean), ('min', np.nanmin), ('max', np.nanmax)]:\n",
    "                data[n + '_' + num_col + '_by_' + cat_col] = sales_train2.groupby(cat_col)[num_col].transform(f)\n",
    "                \n",
    "    # create features with counts\n",
    "    for col in ['shop_id', 'item_id', 'item_category_id', 'city', 'global_category', 'item_price']:\n",
    "        data[col + '_cnt'] = data[col].map(sales_train2[col].value_counts(dropna = False))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "561b5daa",
   "metadata": {},
   "source": [
    "# Replace rare values with \"RARE VALUE\" string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d54db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_col_with_min_freq(data, col, min_freq=10):\n",
    "    # replace rare values (less than min_freq rows) in feature by RARE_VALUE\n",
    "    data[col + '_fixed'] = data[col].astype(str)\n",
    "    data.loc[sales_train2[col].value_counts()[data[col + '_fixed']].values < min_freq, col + \n",
    "             '_fixed'] = \"RARE_VALUE\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5520f633",
   "metadata": {},
   "source": [
    "# Get data from previous month(s) for timeseries prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6420c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cols = [c for c in sales_train2.columns if c.startswith('mean_item_cnt', 0, 13)] + ['item_cnt_month']\n",
    "\n",
    "def create_time_features():\n",
    "    global sales_train2, sales_test2\n",
    "    win = [i for i in range(1, 4)]\n",
    "    for w in win:\n",
    "        tmp = sales_train2[['date_block_num', 'shop_id', 'item_id'] + mean_cols].copy()\n",
    "        tmp.date_block_num = tmp.date_block_num + w\n",
    "        for c in mean_cols:\n",
    "            tmp.rename({c: c + str(w)}, axis=1, inplace=True)\n",
    "\n",
    "        sales_train2 = sales_train2.join(tmp.set_index(['date_block_num', 'shop_id', 'item_id']), \n",
    "                                         on=['date_block_num', 'shop_id', 'item_id'])\n",
    "        sales_test2 = sales_test2.join(tmp.set_index(['date_block_num', 'shop_id', 'item_id']), \n",
    "                                       on=['date_block_num', 'shop_id', 'item_id'])\n",
    "        del tmp\n",
    "        gc.collect()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c48357cf",
   "metadata": {},
   "source": [
    "# Define if text is English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85323d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isEnglish(s):\n",
    "    ss = \"ª°⭐•®’—–™&\\xa0\\xad\\xe2\\xf0\"  # special characters\n",
    "    s = str(s).lower()\n",
    "    for k in range(len(ss)):\n",
    "        s = s.replace(ss[k], \"\")\n",
    "    try:\n",
    "        s.encode(encoding=\"utf-8\").decode(\"ascii\")\n",
    "    except UnicodeDecodeError:\n",
    "        # not english; check it still not english if western european characters are removed\n",
    "        ss = \"éáñóüäýöçãõúíàêôūâşè\"\n",
    "        for k in range(len(ss)):\n",
    "            s = s.replace(ss[k], \"\")\n",
    "        try:\n",
    "            s.encode(encoding=\"utf-8\").decode(\"ascii\")\n",
    "        except UnicodeDecodeError:\n",
    "            return 3  # really not english\n",
    "        else:\n",
    "            return 2  # spanish/french?\n",
    "    else:\n",
    "        return 1  # english"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7e4596a",
   "metadata": {},
   "source": [
    "# Convert japaneese alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc85e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_japanese_alphabet(df):\n",
    "    kakasi = pykakasi.kakasi()\n",
    "    kakasi.setMode('H', 'a')  # Convert Hiragana into alphabet\n",
    "    kakasi.setMode('K', 'a')  # Convert Katakana into alphabet\n",
    "    kakasi.setMode('J', 'a')  # Convert Kanji into alphabet\n",
    "    conversion = kakasi.getConverter()\n",
    "\n",
    "    def convert(row):\n",
    "        for column in [\"name\", \"address\", \"city\", \"state\"]:\n",
    "            try:\n",
    "                row[column] = conversion.do(row[column])\n",
    "            except Exception:\n",
    "                pass\n",
    "        return row\n",
    "\n",
    "    df = df.apply(convert, axis=1)\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "492d2774",
   "metadata": {},
   "source": [
    "# Process some categorical like features (couple of categories in one string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17a0b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categories(cat, split=\" \"):\n",
    "    cat = [x for x in str(cat).split(split) if cat != \"\" and len(x) >= 2]\n",
    "    # Keep only letters\n",
    "    cat = [re.sub(r\"[^a-zA-Z]\", \" \", x) for x in cat]\n",
    "    # Delete multi space\n",
    "    cat = [re.sub(\"\\\\s+\", \" \", x).strip() for x in cat]\n",
    "    return cat\n",
    "\n",
    "# Function to fill missing categories\n",
    "def find_cat(name, Key_words_for_cat):\n",
    "    name_list = process_categories(unidecode(str(name).lower()))\n",
    "    for cat, wordlist in Key_words_for_cat.items():\n",
    "        if any(name_word in name_list for name_word in wordlist):\n",
    "            return cat\n",
    "    return \"\"\n",
    "\n",
    "def process_text_cat(text):\n",
    "    text = unidecode(text.lower())\n",
    "    res = \" \".join([re.sub(r\"[^a-zA-Z]\", \" \", x).strip() for x in text.split()])\n",
    "    return re.sub(\"\\\\s+\", \" \", res).strip()\n",
    "\n",
    "\n",
    "def simplify_cat(categories, Cat_regroup):\n",
    "    categories = str(categories).lower()\n",
    "    if categories in (\"\", \"nan\"):\n",
    "        return -1\n",
    "    for cat in categories.split(\",\"):\n",
    "        cat = process_text_cat(cat)\n",
    "        for i, Liste in enumerate(Cat_regroup):\n",
    "            if any(cat == x for x in Liste):\n",
    "                return i + 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56839783",
   "metadata": {},
   "source": [
    "# Set all features combinations (brute force)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a58fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "features = df.drop(['f_1', 'target'], axis=1).columns\n",
    "generated_features = pd.DataFrame()\n",
    "\n",
    "# with all of these features usually will work too long, so try to comment some of them \n",
    "# and select features separately\n",
    "for fe_a, fe_b in itertools.combinations(features, 2):\n",
    "\n",
    "    generated_features[f'{fe_a}+{fe_b}']   = df[fe_a] + df[fe_b]\n",
    "    generated_features[f'{fe_a}-{fe_b}']   = df[fe_a] - df[fe_b] \n",
    "    generated_features[f'{fe_a}*{fe_b}']   = df[fe_a] * df[fe_b]\n",
    "    generated_features[f'{fe_a}/{fe_b}']   = df[fe_a] / df[fe_b]\n",
    "\n",
    "    generated_features[f'{fe_a}*{fe_b}_2'] = df[fe_a] * df[fe_b].pow(2)\n",
    "    generated_features[f'{fe_a}_2*{fe_b}'] = df[fe_a].pow(2) * df[fe_b]\n",
    "    generated_features[f'{fe_a}_2']        = df[fe_a].pow(2)\n",
    "    generated_features[f'{fe_b}_2']        = df[fe_b].pow(2)\n",
    "\n",
    "    generated_features[f'{fe_a}_05'] = df[fe_a].pow(0.5)\n",
    "    generated_features[f'{fe_b}_05'] = df[fe_b].pow(0.5)\n",
    "    generated_features[f'{fe_a}*{fe_b}_05'] = df[fe_a] * df[fe_b].pow(0.5)\n",
    "    generated_features[f'{fe_a}_05*{fe_b}'] = df[fe_a].pow(0.5) * df[fe_b]\n",
    "    \n",
    "    generated_features[f'{fe_a}_log'] = np.log(df[fe_a])\n",
    "    generated_features[f'{fe_b}_log'] = np.log(df[fe_b])\n",
    "    generated_features[f'{fe_a}*{fe_b}_log'] = df[fe_a] * np.log(df[fe_b])\n",
    "    generated_features[f'{fe_a}_log*{fe_b}'] = np.log(df[fe_a]) * df[fe_b]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b085807",
   "metadata": {},
   "source": [
    "# Create features with PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6031d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# train set\n",
    "poly_train = PolynomialFeatures()\n",
    "data_transform = df.drop('Class', axis=1).copy()\n",
    "data_poly = pd.DataFrame(poly_train.fit_transform(data_transform),\n",
    "                         columns=poly_train.get_feature_names_out(), index=data_transform.index)\n",
    "data_poly = data_poly.drop('1', axis=1)\n",
    "data_poly = pd.concat([data_poly, df[['Class']]], axis=1)\n",
    "data_poly['Class'] = data_poly.Class.astype('int64')\n",
    "\n",
    "# test set\n",
    "poly_test = PolynomialFeatures()\n",
    "test_poly = pd.DataFrame(poly_test.fit_transform(test_df), columns=poly_test.get_feature_names_out())\n",
    "test_poly = test_poly.drop('1', axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "524eabd5",
   "metadata": {},
   "source": [
    "# Create feature interaction using trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0a572f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
