{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e53dfd2d",
   "metadata": {},
   "source": [
    "# CatBoost Encoding for Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba8c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as encoders\n",
    "\n",
    "# Load the CatBoost Encoder \n",
    "CATBoostENCODE = encoders.CatBoostEncoder()\n",
    "\n",
    "categorical_cols = ['EJ']\n",
    "\n",
    "# Use CatBoost to encode the categorical values\n",
    "encoder_train = CATBoostENCODE.fit_transform(train_df[categorical_cols].astype('category'), train_df['Class'])\n",
    "train_df[categorical_cols] = encoder_train\n",
    "\n",
    "encoder_test = CATBoostENCODE.transform(test_df[categorical_cols].astype('category'))\n",
    "test_df[categorical_cols] = encoder_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c20c3d4",
   "metadata": {},
   "source": [
    "# Greedy Binning\n",
    "\n",
    "Can be used to prepare data for NNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b058a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils import *\n",
    "\n",
    "root = args.root\n",
    "\n",
    "oof = pd.read_csv('./output/LGB_with_series_feature/oof.csv')\n",
    "sub = pd.read_csv('./output/LGB_with_series_feature/submission.csv.zip')\n",
    "\n",
    "def pad_target(x):\n",
    "    t = np.zeros(13)\n",
    "    t[:-len(x)] = np.nan\n",
    "    t[-len(x):] = x\n",
    "    return list(t)\n",
    "\n",
    "tmp1 = oof.groupby('customer_ID',sort=False)['target'].agg(lambda x:pad_target(x))\n",
    "tmp2 = sub.groupby('customer_ID',sort=False)['prediction'].agg(lambda x:pad_target(x))\n",
    "\n",
    "tmp = tmp1.append(tmp2)\n",
    "\n",
    "tmp = pd.DataFrame(data=tmp.tolist(),columns=['target%s'%i for i in range(1,14)])\n",
    "\n",
    "\n",
    "df = []\n",
    "for fn in ['cat','num','diff','rank_num','last3_cat','last3_num','last3_diff', 'last6_num','ym_rank_num']:\n",
    "    if len(df) == 0:\n",
    "        df.append(pd.read_feather(f'{root}/{fn}_feature.feather'))\n",
    "    else:\n",
    "        df.append(pd.read_feather(f'{root}/{fn}_feature.feather').drop([id_name],axis=1))\n",
    "    if 'last' in fn :\n",
    "        df[-1] = df[-1].add_prefix('_'.join(fn.split('_')[:-1])+'_')\n",
    "\n",
    "df.append(tmp)\n",
    "\n",
    "df = pd.concat(df,axis=1)\n",
    "print(df.shape)\n",
    "df.to_feather(f'{root}/all_feature.feather')\n",
    "\n",
    "del df\n",
    "\n",
    "def one_hot_encoding(df,cols,is_drop=True):\n",
    "    for col in cols:\n",
    "        print('one hot encoding:',col)\n",
    "        dummies = pd.get_dummies(pd.Series(df[col]),prefix='oneHot_%s'%col)\n",
    "        df = pd.concat([df,dummies],axis=1)\n",
    "    if is_drop:\n",
    "        df.drop(cols,axis=1,inplace=True)\n",
    "    return df\n",
    "\n",
    "cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "\n",
    "df = pd.read_feather(f'./input/train.feather').append(pd.read_feather(f'./input/test.feather')).reset_index(drop=True)\n",
    "df = df.drop(['S_2'],axis=1)\n",
    "df = one_hot_encoding(df,cat_features,True)\n",
    "for col in tqdm(df.columns):\n",
    "    if col not in ['customer_ID','S_2']:\n",
    "        df[col] /= 100\n",
    "    df[col] = df[col].fillna(0)\n",
    "\n",
    "df.to_feather('./input/nn_series.feather')\n",
    "\n",
    "def GreedyFindBin(distinct_values, counts, num_distinct_values, max_bin, total_cnt, min_data_in_bin=3):\n",
    "# INPUT:\n",
    "#   distinct_values - the array of distinct feature values, the feature values are monotonically increasing\n",
    "#   counts - the number of samples that corresponds to the value of the feature\n",
    "#   num_distinct_values - the number of feature values\n",
    "#   max_bin - max number of buckets\n",
    "#   total_cnt - number of samples\n",
    "#   min_data_in_bin - min number of samples that bucket contains\n",
    "\n",
    "# bin_upper_bound - it's an array of record bucket boundaries\n",
    "    bin_upper_bound=list()\n",
    "    assert(max_bin>0)\n",
    "\n",
    "    if num_distinct_values <= max_bin:\n",
    "        cur_cnt_inbin = 0\n",
    "        for i in range(num_distinct_values-1):\n",
    "            cur_cnt_inbin += counts[i]\n",
    "            # If the value ratio of a feature 'min_data_in_bin' is small, accumulate the next value，\n",
    "            # until than 'min_data_in_bin' is greater\n",
    "            if cur_cnt_inbin >= min_data_in_bin:\n",
    "                # Take the mean of the current value and the next value as the cut-off point of the bucket \n",
    "                # 'bin_upper_bound'\n",
    "                bin_upper_bound.append((distinct_values[i] + distinct_values[i + 1]) / 2.0)\n",
    "                cur_cnt_inbin = 0\n",
    "        # 对于最后一个桶的上界则为无穷大\n",
    "        cur_cnt_inbin += counts[num_distinct_values - 1];\n",
    "        bin_upper_bound.append(float('Inf'))\n",
    "    else:\n",
    "        # The number of feature values is larger than max_bin, \n",
    "        # indicating that several feature values need to share one bin\n",
    "        if min_data_in_bin>0:\n",
    "            max_bin=min(max_bin,total_cnt//min_data_in_bin)\n",
    "            max_bin=max(max_bin,1)\n",
    "        # mean size for one bin\n",
    "        mean_bin_size=total_cnt/max_bin\n",
    "        rest_bin_cnt = max_bin\n",
    "        rest_sample_cnt = total_cnt\n",
    "        # definition of 'is_big_count_value' arrays: Initially set the number \n",
    "        # of each distinct value of the feature to be small（false）\n",
    "        is_big_count_value=[False]*num_distinct_values\n",
    "        # If the number of an eigenvalue is greater than mean_bin_size, then these features need a separate bin\n",
    "        for i in range(num_distinct_values):\n",
    "        # If the number of an eigenvalue is greater than mean_bin_size, \n",
    "        # then set the corresponding eigenvalue is_big_count_value is true\n",
    "            if counts[i] >= mean_bin_size:\n",
    "                is_big_count_value[i] = True\n",
    "                rest_bin_cnt-=1\n",
    "                rest_sample_cnt -= counts[i]\n",
    "        # The number of samples of the remaining feature values is averaged \n",
    "        # for each remaining bin： mean size for one bin\n",
    "        mean_bin_size = rest_sample_cnt/rest_bin_cnt\n",
    "        upper_bounds=[float('Inf')]*max_bin\n",
    "        lower_bounds=[float('Inf')]*max_bin\n",
    "\n",
    "        bin_cnt = 0\n",
    "        lower_bounds[bin_cnt] = distinct_values[0]\n",
    "        cur_cnt_inbin = 0\n",
    "        # Re-traverse all eigenvalues (including large and small numbers)\n",
    "        for i in range(num_distinct_values-1):\n",
    "            # If the current number of eigenvalues is small\n",
    "            if not is_big_count_value[i]:\n",
    "                rest_sample_cnt -= counts[i]\n",
    "            cur_cnt_inbin += counts[i]\n",
    "\n",
    "            # like cur_cnt_in bin if it is too small, accumulate the next value \n",
    "            # until the condition is met and enter the loop.\n",
    "            # need a new bin if the current feature needs to be separated into a bin，\n",
    "            # or the current count of several features exceeds mean_bin_size，\n",
    "            # or the next one needs to be bucketed independently\n",
    "            if is_big_count_value[i] or cur_cnt_inbin >= mean_bin_size or \\\n",
    "            is_big_count_value[i + 1] and cur_cnt_inbin >= max(1.0, mean_bin_size * 0.5):\n",
    "                upper_bounds[bin_cnt] = distinct_values[i]\n",
    "                bin_cnt+=1\n",
    "                lower_bounds[bin_cnt] = distinct_values[i + 1] \n",
    "                if bin_cnt >= max_bin - 1:\n",
    "                    break\n",
    "                cur_cnt_inbin = 0\n",
    "                if not is_big_count_value[i]:\n",
    "                    rest_bin_cnt-=1\n",
    "                    mean_bin_size = rest_sample_cnt / rest_bin_cnt\n",
    "#             bin_cnt+=1\n",
    "        # update bin upper bound compared with the number of feature values max_bin\n",
    "        # a small number of operations are similar, taking the mean of the current value \n",
    "        # and the next value as the dividing point of the bucket\n",
    "        for i in range(bin_cnt-1):\n",
    "            bin_upper_bound.append((upper_bounds[i] + lower_bounds[i + 1]) / 2.0)\n",
    "        bin_upper_bound.append(float('Inf'))\n",
    "    return bin_upper_bound\n",
    "\n",
    "cat_features = [\"B_30\",\"B_38\",\"D_114\",\"D_116\",\"D_117\",\"D_120\",\"D_126\",\"D_63\",\"D_64\",\"D_66\",\"D_68\"]\n",
    "eps = 1e-3\n",
    "\n",
    "dfs = []\n",
    "for fn in ['cat','num','diff','rank_num','last3_cat','last3_num','last3_diff', 'last6_num','ym_rank_num']:\n",
    "    if len(dfs) == 0:\n",
    "        dfs.append(pd.read_feather(f'{root}/{fn}_feature.feather'))\n",
    "    else:\n",
    "        dfs.append(pd.read_feather(f'{root}/{fn}_feature.feather').drop(['customer_ID'],axis=1))\n",
    "\n",
    "    if 'last' in fn:\n",
    "        dfs[-1] = dfs[-1].add_prefix('_'.join(fn.split('_')[:-1])+'_')\n",
    "\n",
    "for df in dfs:\n",
    "    for col in tqdm(df.columns):\n",
    "        if col not in ['customer_ID','S_2']:\n",
    "            # v_min = df[col].min()\n",
    "            # v_max = df[col].max()\n",
    "            # df[col] = (df[col]-v_min+eps) / (v_max-v_min+eps)\n",
    "            vc = df[col].value_counts().sort_index()\n",
    "            bins = GreedyFindBin(vc.index.values,vc.values,len(vc),255,vc.sum())\n",
    "            df[col] = np.digitize(df[col],[-np.inf]+bins)\n",
    "            df.loc[df[col]==len(bins)+1,col] = 0\n",
    "            df[col] = df[col] / df[col].max()\n",
    "\n",
    "tmp = tmp.fillna(0)\n",
    "dfs.append(tmp)\n",
    "df = pd.concat(dfs,axis=1)\n",
    "\n",
    "df.to_feather('./input/nn_all_feature.feather')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6a7ee5be",
   "metadata": {},
   "source": [
    "# MCA (like PCA but for categorical values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c34e4ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Color</th>\n",
       "      <th>Size</th>\n",
       "      <th>Action</th>\n",
       "      <th>Age</th>\n",
       "      <th>Inflated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YELLOW</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>STRETCH</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>YELLOW</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>STRETCH</td>\n",
       "      <td>CHILD</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YELLOW</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>DIP</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>YELLOW</td>\n",
       "      <td>SMALL</td>\n",
       "      <td>DIP</td>\n",
       "      <td>CHILD</td>\n",
       "      <td>F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>YELLOW</td>\n",
       "      <td>LARGE</td>\n",
       "      <td>STRETCH</td>\n",
       "      <td>ADULT</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Color   Size   Action    Age Inflated\n",
       "0  YELLOW  SMALL  STRETCH  ADULT        T\n",
       "1  YELLOW  SMALL  STRETCH  CHILD        F\n",
       "2  YELLOW  SMALL      DIP  ADULT        F\n",
       "3  YELLOW  SMALL      DIP  CHILD        F\n",
       "4  YELLOW  LARGE  STRETCH  ADULT        T"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
      "/home/alex/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/home/alex/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/home/alex/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:767: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-34fb1d985e5345e3a18ea8234a8cc300.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-34fb1d985e5345e3a18ea8234a8cc300.vega-embed details,\n",
       "  #altair-viz-34fb1d985e5345e3a18ea8234a8cc300.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-34fb1d985e5345e3a18ea8234a8cc300\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-34fb1d985e5345e3a18ea8234a8cc300\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-34fb1d985e5345e3a18ea8234a8cc300\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.16.3?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.16.3\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"data\": {\"name\": \"data-0c09a753d8a68d5cc06074b89afc0be1\"}, \"mark\": {\"type\": \"circle\", \"size\": 50}, \"encoding\": {\"color\": {\"field\": \"variable\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"variable\", \"type\": \"nominal\"}, {\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"component 0\", \"type\": \"quantitative\"}, {\"field\": \"component 1\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"title\": \"component 0 \\u2014 40.17%\"}, \"field\": \"component 0\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"component 1 \\u2014 21.11%\"}, \"field\": \"component 1\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}, \"name\": \"view_9\"}, {\"data\": {\"name\": \"data-0c09a753d8a68d5cc06074b89afc0be1\"}, \"mark\": {\"type\": \"text\"}, \"encoding\": {\"text\": {\"field\": \"label\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"title\": \"component 0 \\u2014 40.17%\"}, \"field\": \"component 0\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"component 1 \\u2014 21.11%\"}, \"field\": \"component 1\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-71c58439f5eb695812ac0c247adcfc19\"}, \"mark\": {\"type\": \"circle\", \"size\": 50}, \"encoding\": {\"color\": {\"field\": \"variable\", \"type\": \"nominal\"}, \"tooltip\": [{\"field\": \"variable\", \"type\": \"nominal\"}, {\"field\": \"value\", \"type\": \"nominal\"}, {\"field\": \"component 0\", \"type\": \"quantitative\"}, {\"field\": \"component 1\", \"type\": \"quantitative\"}], \"x\": {\"axis\": {\"title\": \"component 0 \\u2014 40.17%\"}, \"field\": \"component 0\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"component 1 \\u2014 21.11%\"}, \"field\": \"component 1\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}, {\"data\": {\"name\": \"data-71c58439f5eb695812ac0c247adcfc19\"}, \"mark\": {\"type\": \"text\"}, \"encoding\": {\"text\": {\"field\": \"label\", \"type\": \"nominal\"}, \"x\": {\"axis\": {\"title\": \"component 0 \\u2014 40.17%\"}, \"field\": \"component 0\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}, \"y\": {\"axis\": {\"title\": \"component 1 \\u2014 21.11%\"}, \"field\": \"component 1\", \"scale\": {\"zero\": false}, \"type\": \"quantitative\"}}}], \"params\": [{\"name\": \"param_11\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\", \"views\": [\"view_9\"]}], \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.16.3.json\", \"datasets\": {\"data-0c09a753d8a68d5cc06074b89afc0be1\": [{\"component 0\": 0.7053867996248334, \"component 1\": 1.0676994688088876e-14, \"component 2\": 0.7586391105690964, \"variable\": \"row\", \"value\": \"0\", \"label\": 0}, {\"component 0\": -0.38658629949599044, \"component 1\": 8.778640419619736e-15, \"component 2\": 0.6260630816840029, \"variable\": \"row\", \"value\": \"1\", \"label\": 1}, {\"component 0\": -0.3865862994959898, \"component 1\": 7.84208052007809e-15, \"component 2\": 0.626063081684002, \"variable\": \"row\", \"value\": \"2\", \"label\": 2}, {\"component 0\": -0.8520140574664054, \"component 1\": 7.155658391739587e-15, \"component 2\": 0.5624474892356499, \"variable\": \"row\", \"value\": \"3\", \"label\": 3}, {\"component 0\": 0.7835387510478189, \"component 1\": -0.6333333333333311, \"component 2\": 0.13020069134919057, \"variable\": \"row\", \"value\": \"4\", \"label\": 4}, {\"component 0\": 0.7835387510478189, \"component 1\": -0.6333333333333311, \"component 2\": 0.13020069134919057, \"variable\": \"row\", \"value\": \"5\", \"label\": 5}, {\"component 0\": -0.3084343480730049, \"component 1\": -0.633333333333333, \"component 2\": -0.002375337535902962, \"variable\": \"row\", \"value\": \"6\", \"label\": 6}, {\"component 0\": -0.3084343480730043, \"component 1\": -0.633333333333334, \"component 2\": -0.002375337535903788, \"variable\": \"row\", \"value\": \"7\", \"label\": 7}, {\"component 0\": -0.7738621060434198, \"component 1\": -0.6333333333333346, \"component 2\": -0.06599092998425597, \"variable\": \"row\", \"value\": \"8\", \"label\": 8}, {\"component 0\": 0.7835387510478186, \"component 1\": 0.6333333333333354, \"component 2\": 0.13020069134917298, \"variable\": \"row\", \"value\": \"9\", \"label\": 9}, {\"component 0\": 0.7835387510478186, \"component 1\": 0.6333333333333354, \"component 2\": 0.13020069134917298, \"variable\": \"row\", \"value\": \"10\", \"label\": 10}, {\"component 0\": -0.30843434807300535, \"component 1\": 0.6333333333333335, \"component 2\": -0.002375337535920559, \"variable\": \"row\", \"value\": \"11\", \"label\": 11}, {\"component 0\": -0.30843434807300474, \"component 1\": 0.6333333333333325, \"component 2\": -0.002375337535921385, \"variable\": \"row\", \"value\": \"12\", \"label\": 12}, {\"component 0\": -0.7738621060434202, \"component 1\": 0.6333333333333319, \"component 2\": -0.06599092998427357, \"variable\": \"row\", \"value\": \"13\", \"label\": 13}, {\"component 0\": 0.861690702470804, \"component 1\": -6.495741682450659e-15, \"component 2\": -0.4982377278707329, \"variable\": \"row\", \"value\": \"14\", \"label\": 14}, {\"component 0\": 0.861690702470804, \"component 1\": -6.495741682450659e-15, \"component 2\": -0.4982377278707329, \"variable\": \"row\", \"value\": \"15\", \"label\": 15}, {\"component 0\": -0.23028239665001982, \"component 1\": -8.394095950919798e-15, \"component 2\": -0.6308137567558263, \"variable\": \"row\", \"value\": \"16\", \"label\": 16}, {\"component 0\": -0.2302823966500192, \"component 1\": -9.330655850461444e-15, \"component 2\": -0.6308137567558272, \"variable\": \"row\", \"value\": \"17\", \"label\": 17}, {\"component 0\": -0.6957101546204347, \"component 1\": -1.0017077978799947e-14, \"component 2\": -0.6944293492041793, \"variable\": \"row\", \"value\": \"18\", \"label\": 18}], \"data-71c58439f5eb695812ac0c247adcfc19\": [{\"component 0\": 0.11730760677191403, \"component 1\": 0.6892024376045022, \"component 2\": -0.6412704755837092, \"variable\": \"column\", \"value\": \"Color_PURPLE\", \"label\": \"Color_PURPLE\"}, {\"component 0\": -0.13034178530212673, \"component 1\": -0.7657804862272246, \"component 2\": 0.7125227506485661, \"variable\": \"column\", \"value\": \"Color_YELLOW\", \"label\": \"Color_YELLOW\"}, {\"component 0\": 0.11730760677191508, \"component 1\": -0.6892024376045195, \"component 2\": -0.6412704755836911, \"variable\": \"column\", \"value\": \"Size_LARGE\", \"label\": \"Size_LARGE\"}, {\"component 0\": -0.13034178530212787, \"component 1\": 0.7657804862272437, \"component 2\": 0.7125227506485461, \"variable\": \"column\", \"value\": \"Size_SMALL\", \"label\": \"Size_SMALL\"}, {\"component 0\": -0.8538641988881542, \"component 1\": -1.904907771823469e-15, \"component 2\": -0.07934001340795416, \"variable\": \"column\", \"value\": \"Action_DIP\", \"label\": \"Action_DIP\"}, {\"component 0\": 0.6209921446459302, \"component 1\": 1.3721461414141147e-15, \"component 2\": 0.05770182793305772, \"variable\": \"column\", \"value\": \"Action_STRETCH\", \"label\": \"Action_STRETCH\"}, {\"component 0\": 0.6209921446459307, \"component 1\": 4.294843385076245e-16, \"component 2\": 0.05770182793305704, \"variable\": \"column\", \"value\": \"Age_ADULT\", \"label\": \"Age_ADULT\"}, {\"component 0\": -0.8538641988881545, \"component 1\": -4.785053821641639e-16, \"component 2\": -0.07934001340795324, \"variable\": \"column\", \"value\": \"Age_CHILD\", \"label\": \"Age_CHILD\"}, {\"component 0\": -0.7314664035372919, \"component 1\": -7.573022452650938e-16, \"component 2\": -0.054731083980793224, \"variable\": \"column\", \"value\": \"Inflated_F\", \"label\": \"Inflated_F\"}, {\"component 0\": 1.253942406063929, \"component 1\": 1.380950736427573e-15, \"component 2\": 0.09382471539564581, \"variable\": \"column\", \"value\": \"Inflated_T\", \"label\": \"Inflated_T\"}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import prince\n",
    "\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/balloons/adult+stretch.data')\n",
    "df.columns = ['Color', 'Size', 'Action', 'Age', 'Inflated']\n",
    "display(df.head())\n",
    "\n",
    "mca = prince.MCA(n_components = 3)\n",
    "mca = mca.fit(df)\n",
    "ax = mca.plot(df, show_column_labels=True, show_row_labels=True)\n",
    "ax"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
